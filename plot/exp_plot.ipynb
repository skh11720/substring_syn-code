{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, join, splitext\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ceil, log10\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from subprocess import call\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "%run util.ipynb\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotGenerator:\n",
    "    pt_list = [2,3,8,4,6,12,1,10,14]\n",
    "    \n",
    "    def __init__(self, data_info, theta, ymax_offset):\n",
    "        self.data_info = data_info\n",
    "        self.theta = theta\n",
    "        \n",
    "#         self.goal = None\n",
    "        self.xlabel = None\n",
    "#         self.ylabel = None\n",
    "#         self.xrange = None\n",
    "        self.ylabel = 'Avg. exe. time \\(sec\\)'\n",
    "        self.xtics = None\n",
    "        self.xmax = 0\n",
    "        self.ymax = 0\n",
    "        self.ymax_offset = ymax_offset\n",
    "        self.xlog = True\n",
    "        self.xformat = \"10^{%L}\"\n",
    "        \n",
    "        self.title_list = []\n",
    "        self.setting_list = setting_list\n",
    "   \n",
    "    def execute(data_info, theta, ymax_offset=0):\n",
    "        if data_info.size == '*': TimeBySizePlotGenerator(data_info, theta, ymax_offset).run()\n",
    "        elif data_info.qlen == '*': TimeByQlenPlotGenerator(data_info, theta, ymax_offset).run()\n",
    "        elif data_info.nr == '*': TimeByNrulePlotGenerator(data_info, theta, ymax_offset).run()\n",
    "        elif data_info.lr == '*': TimeByLenRatioPlotGenerator(data_info, theta, ymax_offset).run()\n",
    "\n",
    "    def run(self):\n",
    "        self.output_name = '{}__{}__{:.1f}'.format(self.goal, self.data_info.name, self.theta).replace('.', '_')\n",
    "        self.load_df()\n",
    "        self.write_result()\n",
    "        self.output_script()\n",
    "        self.output_plot()\n",
    "        \n",
    "    def load_df(self):\n",
    "        pass\n",
    "        \n",
    "    def parse_row(self, row):\n",
    "        pass\n",
    "\n",
    "    def update_xmax(self, row):\n",
    "        pass\n",
    "    \n",
    "    def update_ymax(self, row):\n",
    "        self.ymax = max(self.ymax, row.Time_SearchPerQuery_MEAN)\n",
    "    \n",
    "    def additional_settings(self, f):\n",
    "        pass\n",
    "    \n",
    "    def write_result(self):\n",
    "        self.path_result = join('result', '{}.result'.format(self.output_name))\n",
    "        df = self.df\n",
    "        with open(self.path_result, 'w') as f:\n",
    "            for setting in self.setting_list:\n",
    "                f.write(\"# {}\\n\".format(setting))\n",
    "                df_target = df[df.theta==self.theta][df.setting==setting]\n",
    "                for row in df_target.itertuples():\n",
    "                    self.update_xmax(row)\n",
    "                    self.update_ymax(row)\n",
    "                    f.write(self.parse_row(row))\n",
    "                f.write('\\n\\n')\n",
    "                self.title_list.append(setting if df_target.size > 0 else None)\n",
    "\n",
    "    \n",
    "    def output_script(self):\n",
    "        self.path_script = join('script', '{}.plot'.format(self.output_name))\n",
    "        self.path_plot = join('plot', '{}.pdf'.format(self.output_name))\n",
    "        with open(self.path_script, 'w') as f:\n",
    "#             f.write('set terminal font \\\",20\\\"\\n')\n",
    "            if self.xlabel is not None: f.write('set xlabel \\\"{}\\\" font \\\",20\\\"\\n'.format(self.xlabel))\n",
    "            f.write('set ylabel \\\"{}\\\" font \\\",20\\\"\\n'.format(self.ylabel))\n",
    "            if self.xtics is not None: f.write('set xtics {}\\n'.format(self.xtics))\n",
    "            f.write('set xtics font \\\",16\"\\n')\n",
    "            f.write('set ytics font \\\",16\\\"\\n')\n",
    "            f.write('set xrange {}\\n'.format(self.xrange))\n",
    "#             f.write('set yrange [*:{}]\\n'.format(10**(ceil(log10(self.ymax))+self.ymax_offset)))\n",
    "            f.write('set yrange [*:{}]\\n'.format(10**(4.5+self.ymax_offset)))\n",
    "            f.write('set key vertical maxrows 5\\n')\n",
    "            if self.xlog:\n",
    "                f.write('set logscale x\\n')\n",
    "                f.write('set format x \\\"{}\\\"\\n'.format(self.xformat))\n",
    "            f.write('set logscale y\\n')\n",
    "            f.write('set format y \\\"10^{%L}\\\"\\n')\n",
    "            f.write('set size 0.6,0.5\\n')\n",
    "            self.additional_settings(f)\n",
    "            \n",
    "\n",
    "            f.write('set term postscript\\n')\n",
    "            f.write('set output\\\"| ps2pdf - {}\\\"\\n'.format(self.path_plot))\n",
    "\n",
    "            cmd_list = []\n",
    "            idx = 0\n",
    "            for tidx, title in enumerate(self.title_list):\n",
    "                if title is None: continue\n",
    "                cmd = '\\\"{}\\\" index {} with linespoints lc \\\"black\\\" lw 2 ps 1.5 dt {} pt {} title \\\"{}\\\"'.format(\n",
    "                self.path_result, idx, tidx+1, PlotGenerator.pt_list[tidx%len(PlotGenerator.pt_list)], title)\n",
    "                cmd_list.append(cmd)\n",
    "                idx += 1\n",
    "            f.write('plot\\\\\\n'+',\\\\\\n'.join(cmd_list))    #',\\\\\\n'.join(cmd_list)\n",
    "    \n",
    "    def output_plot(self):\n",
    "        call(['gnuplot', self.path_script])\n",
    "        call(['sleep', '0.3'])\n",
    "        call(['pdfcrop', self.path_plot, 'tmp_plot'])\n",
    "        call(['mv', 'tmp_plot', self.path_plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeBySizePlotGenerator(PlotGenerator):\n",
    "\n",
    "    def __init__(self, data_info, theta, ymax_offset, alg_list=alg_list, setting_list=setting_list, goal=None):\n",
    "        super(TimeBySizePlotGenerator, self).__init__(data_info, theta, ymax_offset)\n",
    "        self.goal = 'time_by_size' if goal is None else goal\n",
    "        \n",
    "        if self.data_info.name.endswith('-DOC'):\n",
    "#             self.xlabel = 'Number of documents'\n",
    "            self.xrange = '[1000:1000000]'\n",
    "        else:\n",
    "#             self.xlabel = 'Number of strings'\n",
    "            self.xrange = '[10000:10000000]'\n",
    "              \n",
    "        self.xlog = True\n",
    "        self.ymax_offset = ymax_offset\n",
    "        self.alg_list = alg_list\n",
    "        self.setting_list = setting_list\n",
    "\n",
    "    def load_df(self):\n",
    "        self.df = df_time_by_size(self.data_info, self.alg_list)\n",
    "#         if self.data_info.name in ['WIKI', 'AMAZON']:\n",
    "#             self.df.drop( self.df[self.df['n']==10000000].index , inplace=True)\n",
    "#             self.xrange = f\"[{min(self.df['n'])}:{max(self.df['n'])}]\"\n",
    "    \n",
    "    def parse_row(self, row):\n",
    "        if self.data_info.name.endswith('-DOC'):\n",
    "            return '{}\\t{}\\n'.format(row.n_doc, row.Time_SearchPerQuery_MEAN)\n",
    "        else:\n",
    "            return '{}\\t{}\\n'.format(row.n, row.Time_SearchPerQuery_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeByQlenPlotGenerator(PlotGenerator):\n",
    "\n",
    "    def __init__(self, data_info, theta, ymax_offset):\n",
    "        super(TimeByQlenPlotGenerator, self).__init__(data_info, theta, ymax_offset)\n",
    "        self.goal = 'time_by_qlen'\n",
    "#         self.xlabel = 'Query size\n",
    "        self.xrange = '[1:9]'\n",
    "        self.xlog = False\n",
    "        self.ymax_offset = ymax_offset\n",
    "\n",
    "    def load_df(self):\n",
    "        self.df = df_time_by_qlen(self.data_info)\n",
    "    \n",
    "    def parse_row(self, row):\n",
    "        return '{}\\t{}\\n'.format(row.qlen, row.Time_SearchPerQuery_MEAN)\n",
    "    \n",
    "    def additional_settings(self, f):\n",
    "        f.write('set xtics 1,2,9\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeByNrulePlotGenerator(PlotGenerator):\n",
    "\n",
    "    def __init__(self, data_info, theta, ymax_offset):\n",
    "        super(TimeByNrulePlotGenerator, self).__init__(data_info, theta, ymax_offset)\n",
    "        self.goal = 'time_by_nr'\n",
    "#         self.xlabel = 'Number of rules'\n",
    "        self.xrange = '[1000:110000]'\n",
    "        self.xlog = True\n",
    "        self.xformat = \"2{/Symbol\\\\264}10^{%L}\"\n",
    "        \n",
    "    def load_df(self):\n",
    "        self.df = df_time_by_nr(self.data_info)\n",
    "    \n",
    "    def parse_row(self, row):\n",
    "        return '{}\\t{}\\n'.format(row.nr, row.Time_SearchPerQuery_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeByLenRatioPlotGenerator(PlotGenerator):\n",
    "\n",
    "    def __init__(self, data_info, theta, ymax_offset):\n",
    "        super(TimeByLenRatioPlotGenerator, self).__init__(data_info, theta, ymax_offset)\n",
    "        self.goal = 'time_by_lr'\n",
    "#         self.xlabel = 'Ratio of string size'\n",
    "        self.xrange = '[0.2:1.0]'\n",
    "        self.xtics = 0.2\n",
    "        self.xlog = False\n",
    "        self.xformat = \"%.1f\"\n",
    "        \n",
    "    def load_df(self):\n",
    "        self.df = df_time_by_lr(self.data_info)\n",
    "    \n",
    "    def parse_row(self, row):\n",
    "        return '{}\\t{}\\n'.format(row.lr, row.Time_SearchPerQuery_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeByThetaPlotGenerator(PlotGenerator):\n",
    "\n",
    "    def __init__(self, data_info, theta, ymax_offset):\n",
    "        super(TimeByThetaPlotGenerator, self).__init__(data_info, theta, ymax_offset)\n",
    "        self.goal = 'time_by_theta'\n",
    "#         self.xlabel = 'Minimum threshold'\n",
    "        self.xrange = '[0.6:1.0]'\n",
    "        self.xlog = False\n",
    "        \n",
    "    def load_df(self):\n",
    "        self.df = df_time_by_filtering(self.data_info).sort_values('theta').groupby(['theta', 'setting']).head(1)\n",
    "    \n",
    "    def parse_row(self, row):\n",
    "        return '{}\\t{}\\n'.format(row.theta, row.Time_SearchPerQuery_MEAN)\n",
    "    \n",
    "    def additional_settings(self, f):\n",
    "        f.write('set xtics 0.6,0.1,1.0\\n')\n",
    "    \n",
    "    def write_result(self):\n",
    "        self.path_result = join('result', '{}.result'.format(self.output_name))\n",
    "        df = self.df\n",
    "        with open(self.path_result, 'w') as f:\n",
    "            for setting in self.setting_list:\n",
    "                f.write(\"# {}\\n\".format(setting))\n",
    "                df_target = df[df.setting==setting]\n",
    "                for row in df_target.itertuples():\n",
    "                    self.update_xmax(row)\n",
    "                    self.update_ymax(row)\n",
    "                    f.write(self.parse_row(row))\n",
    "                f.write('\\n\\n')\n",
    "                self.title_list.append(setting if df_target.size > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_verify_by_alg(data_info, theta):\n",
    "    goal = 'verify_by_alg'\n",
    "#     df = df_time_by_filtering(data_info)\n",
    "    df = df_from_PrefixSearchFilterPowerTest()\n",
    "    df = df[~pd.isnull(df.setting)]\n",
    "    df = df[df.data_name==data_info.name][df.n==int(data_info.size)][df.nr==int(data_info.nr)][df.qlen==int(data_info.qlen)]\n",
    "    output_name = '{}__{}__{:.1f}'.format(goal, data_info.name, theta).replace('.', '_')\n",
    "    df_target = df[df.theta==theta].sort_values(['setting'])\n",
    "    title_list = []\n",
    "\n",
    "    path_result = join('result', '{}.result'.format(output_name))\n",
    "    if data_info.name == 'WIKI': ymin = 10**2\n",
    "    elif data_info.name == 'PUBMED': ymin = 10**2\n",
    "    elif data_info.name == 'AMAZON': ymin = 10**2\n",
    "    ymax = 10**12\n",
    "    with open(path_result, 'w') as f:\n",
    "        for idx, row in enumerate(df_target.itertuples()): \n",
    "            try: \n",
    "                title = row.setting\n",
    "                title_list.append(title)\n",
    "                f.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(idx, title, row.Num_Verified, row.Num_QS_Verified, row.Num_TS_Verified))\n",
    "#                 ymin = min(ymin, row.Num_Verified)\n",
    "            except: pass\n",
    "\n",
    "    path_script = join('script', '{}.plot'.format(output_name))\n",
    "    path_plot = join('plot', '{}.pdf'.format(output_name))\n",
    "    with open(path_script, 'w') as f:\n",
    "        f.write('set style fill solid border\\n')\n",
    "#         f.write('set xlabel font \\\",20\\\"\\n')\n",
    "        f.write('set ylabel \\\"#Verified pairs\\\" font \\\",20\\\"\\n')\n",
    "        f.write('set yrange [{}:{}]\\n'.format(ymin, ymax))\n",
    "        f.write('set xtics font \\\",16\"\\n')\n",
    "        f.write('set ytics font \\\",16\\\"\\n')\n",
    "        f.write('set key vertical maxrows 5\\n')\n",
    "\n",
    "        f.write('set logscale y\\n')\n",
    "        f.write('set format y \\\"10^{%L}\\\"\\n')\n",
    "    #     f.write('set style fill pattern border -1\\n')\n",
    "        f.write('set boxwidth 0.9\\n')\n",
    "        f.write('set xtics format \\\"\\\"\\n')\n",
    "        f.write('set size 0.6,0.6\\n')\n",
    "\n",
    "        f.write('set term postscript\\n')\n",
    "        f.write('set output\\\"| ps2pdf - {}\\\"\\n'.format(path_plot))\n",
    "\n",
    "        cmd_list = []\n",
    "        for idx, title in enumerate(title_list):\n",
    "            cmd = '\\\"{}\\\" every ::{}::{} using 1:3 with boxes fs pattern {} lw 2 title \\\"{}\\\"'.format(\n",
    "            path_result, idx, idx, idx+2, title)\n",
    "            cmd_list.append(cmd)\n",
    "        f.write('plot\\\\\\n'+',\\\\\\n'.join(cmd_list))\n",
    "\n",
    "    call(['gnuplot', path_script])\n",
    "    call(['sleep', '0.3'])\n",
    "    call(['pdfcrop', path_plot, 'tmp_plot'])\n",
    "    call(['mv', 'tmp_plot', path_plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_time_by_alg(data_info, theta):\n",
    "    goal = 'filter_time_by_alg'\n",
    "#     df = df_time_by_filtering(data_info)\n",
    "    df = df_from_PrefixSearchFilterPowerTest()\n",
    "    df = df[~pd.isnull(df.setting)]\n",
    "    df = df[df.data_name==data_info.name][df.n==int(data_info.size)][df.nr==int(data_info.nr)][df.qlen==int(data_info.qlen)]\n",
    "    output_name = '{}__{}__{:.1f}'.format(goal, data_info.name, theta).replace('.', '_')\n",
    "    df_target = df[df.theta==theta].sort_values(['setting'])\n",
    "    title_list = []\n",
    "\n",
    "    path_result = join('result', '{}.result'.format(output_name))\n",
    "#     if data_info.name == 'WIKI': ymin = 10**3\n",
    "#     elif data_info.name == 'PUBMED': ymin = 10**3\n",
    "#     elif data_info.name == 'AMAZON': ymin = 10**3\n",
    "    ymin = 10**(-1)\n",
    "    ymax = 10**(5.5)\n",
    "    with open(path_result, 'w') as f:\n",
    "        for idx, row in enumerate(df_target.itertuples()): \n",
    "            try: \n",
    "                title = row.setting\n",
    "                title_list.append(title)\n",
    "                f.write('{}\\t{}\\t{}\\n'.format(idx, title, row.Time_Total))\n",
    "#                 ymin = min(ymin, row.Num_Verified)\n",
    "            except: pass\n",
    "\n",
    "    path_script = join('script', '{}.plot'.format(output_name))\n",
    "    path_plot = join('plot', '{}.pdf'.format(output_name))\n",
    "    with open(path_script, 'w') as f:\n",
    "        f.write('set style fill solid border\\n')\n",
    "#         f.write('set xlabel font \\\",20\\\"\\n')\n",
    "        f.write('set ylabel \\\"#Verified pairs\\\" font \\\",20\\\"\\n')\n",
    "        f.write('set yrange [{}:{}]\\n'.format(ymin, ymax))\n",
    "        f.write('set xtics font \\\",16\"\\n')\n",
    "        f.write('set ytics font \\\",16\\\"\\n')\n",
    "        f.write('set key vertical maxrows 5\\n')\n",
    "\n",
    "        f.write('set logscale y\\n')\n",
    "        f.write('set format y \\\"10^{%L}\\\"\\n')\n",
    "    #     f.write('set style fill pattern border -1\\n')\n",
    "        f.write('set boxwidth 0.9\\n')\n",
    "        f.write('set xtics format \\\"\\\"\\n')\n",
    "        f.write('set size 0.6,0.6\\n')\n",
    "\n",
    "        f.write('set term postscript\\n')\n",
    "        f.write('set output\\\"| ps2pdf - {}\\\"\\n'.format(path_plot))\n",
    "\n",
    "        cmd_list = []\n",
    "        for idx, title in enumerate(title_list):\n",
    "            cmd = '\\\"{}\\\" every ::{}::{} using 1:3 with boxes fs pattern {} lw 2 title \\\"{}\\\"'.format(\n",
    "            path_result, idx, idx, idx+2, title)\n",
    "            cmd_list.append(cmd)\n",
    "        f.write('plot\\\\\\n'+',\\\\\\n'.join(cmd_list))\n",
    "\n",
    "    call(['gnuplot', path_script])\n",
    "    call(['sleep', '0.3'])\n",
    "    call(['pdfcrop', path_plot, 'tmp_plot'])\n",
    "    call(['mv', 'tmp_plot', path_plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_index_build_time(varying, theta=0.7):\n",
    "    goal = 'index_build_time'\n",
    "    n0 = '1000000'\n",
    "    q0 = '5'\n",
    "    lr0 = '1.0'\n",
    "    output_name = '{}__{}'.format(goal, varying).replace('.', '_')\n",
    "    title_list = ['WIKI', 'PUBMED', 'AMAZON']\n",
    "    \n",
    "    if varying == 'nt': \n",
    "        data_info_list = [DataInfo('WIKI', '*', '107836', q0, lr0), DataInfo('PUBMED', '*', '79011', q0, lr0), DataInfo('AMAZON', '*', '107836', q0, lr0),]\n",
    "        xlabel = '\\#strings'\n",
    "        xrange = '[10000:1000000]'\n",
    "        xformat = \"10^{%L}\"\n",
    "    elif varying == 'nr': \n",
    "        data_info_list = [DataInfo('WIKI', n0, '*', q0, lr0), DataInfo('PUBMED', n0, '*', q0, lr0), DataInfo('AMAZON', n0, '*', q0, lr0),]\n",
    "        xlabel = '\\#rules'\n",
    "        xrange = '[1000:110000]'\n",
    "        xformat = \"2{/Symbol\\\\264}10^{%L}\"\n",
    "    \n",
    "    path_result = join('result', '{}.result'.format(output_name))\n",
    "    with open(path_result, 'w') as f:\n",
    "        for data_info in data_info_list:\n",
    "            if varying == 'nt':\n",
    "                df = df_time_by_size(data_info)\n",
    "                df = df[df.theta==theta][df.setting=='PF'][['n', 'Time_BuildIndex']]\n",
    "            elif varying == 'nr':\n",
    "                df = df_time_by_nr(data_info)\n",
    "                df = df[df.theta==theta][df.setting=='PF'][['nr', 'Time_BuildIndex']]\n",
    "\n",
    "            for row in df.itertuples(): \n",
    "                try: \n",
    "                    f.write('{}\\t{}\\n'.format(row[1], row[2]))\n",
    "    #                 ymin = min(ymin, row.Num_Verified)\n",
    "                except: pass\n",
    "            f.write('\\n\\n')\n",
    "\n",
    "    path_script = join('script', '{}.plot'.format(output_name))\n",
    "    path_plot = join('plot', '{}.pdf'.format(output_name))\n",
    "    with open(path_script, 'w') as f:\n",
    "        f.write('set xlabel \\\"{}\\\" font \\\",20\\\"\\n'.format(xlabel))\n",
    "        f.write('set ylabel \\\"{}\\\" font \\\",20\\\"\\n'.format(\"Time \\(sec\\)\"))\n",
    "        f.write('set xtics font \\\",16\"\\n')\n",
    "        f.write('set ytics font \\\",16\\\"\\n')\n",
    "        f.write('set xrange {}\\n'.format(xrange))\n",
    "#         f.write('set yrange [*:{}]\\n'.format(10**(ceil(log10(self.ymax))+self.ymax_offset)))\n",
    "#         f.write('set key vertical maxrows 4\\n')\n",
    "        f.write('set logscale x\\n')\n",
    "        f.write('set format x \\\"{}\\\"\\n'.format(xformat))\n",
    "        f.write('set logscale y\\n')\n",
    "        f.write('set format y \\\"10^{%L}\\\"\\n')\n",
    "        f.write('set size 0.6,0.6\\n')\n",
    "\n",
    "        f.write('set term postscript\\n')\n",
    "        f.write('set output\\\"| ps2pdf - {}\\\"\\n'.format(path_plot))\n",
    "\n",
    "        cmd_list = []\n",
    "        for idx, title in enumerate(title_list):\n",
    "            cmd = '\\\"{}\\\" index {} with linespoints lc \\\"black\\\" lw 2 ps 1.5 dt {} pt {} title \\\"{}\\\"'.format(\n",
    "            path_result, idx, idx+1, PlotGenerator.pt_list[idx%len(PlotGenerator.pt_list)], title_list[idx])\n",
    "            cmd_list.append(cmd)\n",
    "        f.write('plot\\\\\\n'+',\\\\\\n'.join(cmd_list))    #',\\\\\\n'.join(cmd_list)\n",
    "\n",
    "    call(['gnuplot', path_script])\n",
    "    call(['sleep', '0.3'])\n",
    "    call(['pdfcrop', path_plot, 'tmp_plot'])\n",
    "    call(['mv', 'tmp_plot', path_plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tex_data_stat():\n",
    "    df = pd.read_csv('DataStat.txt', sep='\\t', names=['label', 'n_doc', 'nt', 'n_tokens', 'nr', 'nSnt_min', 'nSnt_max', 'nSnt_mean', 'nSnt_var', 'len_min', 'len_max', 'len_mean', 'len_var', 'na_min', 'na_max', 'na_mean', 'na_var'])\n",
    "\n",
    "    SEP = ' & '\n",
    "    EOL = ' \\\\\\\\\\\\hline'\n",
    "    df0 = df[df.n_doc==0][['nt', 'n_tokens', 'nr', 'len_mean', 'na_mean']]\n",
    "    row_headers = [\"\\# of strings\", \"\\# of distinct tokens\", \"\\# of rules\", \"\\makecell{Avg. string size}\", \"\\makecell{Avg. \\# of applicable rules}\", ]\n",
    "    for header, row in zip(row_headers, df0.items()):\n",
    "        val_list = row[1].tolist()\n",
    "        if type(val_list[0]) == int: print(header+SEP+SEP.join(map(lambda x: f\"{x:,}\", val_list))+EOL)\n",
    "        elif type(val_list[0]) == float: print(header+SEP+SEP.join(map(lambda x: f\"{x:.3f}\", val_list))+EOL)\n",
    "    print()\n",
    "\n",
    "    df1 = df[df.n_doc>0][['n_doc', 'nt', 'n_tokens', 'nSnt_mean']]\n",
    "    row_headers = [\"\\# of documents\", \"\\# of strings\", \"\\# of distinct tokens\", \"\\makecell{Avg. \\# of strings in a document}\", ]\n",
    "    for header, row in zip(row_headers, df1.items()):\n",
    "        val_list = row[1].tolist()\n",
    "        if type(val_list[0]) == int: print(header+SEP+SEP.join(map(lambda x: f\"{x:,}\", val_list))+EOL)\n",
    "        elif type(val_list[0]) == float: print(header+SEP+SEP.join(map(lambda x: f\"{x:.3f}\", val_list))+EOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tex_heuristic_accuracy():\n",
    "#     df = df_heuristic_accuracy()\n",
    "#     for theta in [0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "#         line = ''\n",
    "#         line += '{:.1f}'.format(theta)\n",
    "#         for data_name in ['WIKI', 'PUBMED', 'AMAZON']:\n",
    "#             row = df[df.theta==theta][df.data_name==data_name]\n",
    "#             for side in ['QS', 'TS']:\n",
    "#                 line += ' & {:.4f}'.format(row['Acc_{}'.format(side)].values[0])\n",
    "#         print(line+' \\\\\\\\\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tex_heuristic_accuracy():\n",
    "    SEP = ' & '\n",
    "    EOL = ' \\\\\\\\\\\\hline'\n",
    "    dataset_list = ['WIKI', 'AMAZON', 'PUBMED']\n",
    "    outputs = []\n",
    "    with open('val_acc_result.txt') as f:\n",
    "        for line in f: outputs.append(dict(map(lambda x:x.split('='), line.strip().split('\\t'))))\n",
    "    df = pd.DataFrame(outputs)\n",
    "    df['dataset'] = list(map(lambda x:x.split('_')[0], df['dataset'].tolist()))\n",
    "    df = df.astype({'avgdiff_Q':float, 'avgdiff_T':float, 'nQ1/nQ0':float, 'nT1/nT0':float})\n",
    "    for theta in ['0.5', '0.6', '0.7', '0.8', '0.9', '1.0']:\n",
    "        line = theta\n",
    "        for dataset in dataset_list:\n",
    "            acc_Q, acc_T = df[df.theta==theta][df.dataset==dataset][['nQ1/nQ0', 'nT1/nT0']].values[0].tolist()\n",
    "            line += SEP + f\"{acc_Q:.4f}\" + SEP + f\"{acc_T:.4f}\"\n",
    "        line += EOL\n",
    "        print(line)\n",
    "    print()\n",
    "    for theta in ['0.5', '0.6', '0.7', '0.8', '0.9', '1.0']:\n",
    "        line = theta\n",
    "        for dataset in dataset_list:\n",
    "            acc_Q, acc_T = df[df.theta==theta][df.dataset==dataset][['avgdiff_Q', 'avgdiff_T']].values[0].tolist()\n",
    "            line += SEP + f\"{acc_Q:.2e}\" + SEP + f\"{acc_T:.2e}\"\n",
    "        line += EOL\n",
    "        print(line)\n",
    "# tex_heuristic_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tex_table_filter_power(attr, setting_list=None):\n",
    "    assert attr in ['Time_SearchPerQuery_MEAN', 'Num_Verified', 'Len_Verified']\n",
    "    if setting_list is None:\n",
    "        setting_list = ['RSS-NAIVE', 'RSS-C', 'RSS-P', 'RSS-L', 'RSS-R', 'RSS-CL', 'RSS-PL', 'RSS-CP', 'RSS-CR', 'RSS-PR', 'PKDUCK-W', 'RSS-CPL', 'RSS-CPR', 'RSS-CLR', 'RSS-PLR', 'RSS-CPLR']\n",
    "    datainfo_list = [\n",
    "            DataInfo('WIKI', '*', '107836', '5', '1.0', '-1'),\n",
    "#             DataInfo('PUBMED', '*', '79011', '5', '1.0', '-1'),\n",
    "#             DataInfo('AMAZON', '*', '107836', '5', '1.0', '-1'),\n",
    "    ]\n",
    "    df = df_from_PrefixSearchFilterPowerTest(setting_list, path='ZeroPrefixSearch.out.repeat10')\n",
    "\n",
    "    print((' & '.join(['\\\\multirow{2}{*}{$\\\\theta$}']+list(map(lambda x:'\\\\makecell[c]{\\\\textit{'+x+'}}', setting_list)))).replace('RSS-', '').replace('PKDUCK-W', 'LR') +' \\\\\\\\\\\\hline')\n",
    "    for datainfo in datainfo_list:\n",
    "        df0 = df[df.data_name==datainfo.name][~pd.isnull(df.setting)][df.n==100000][df.nr==int(datainfo.nr)][df.theta>=0.7][df.qlen==int(datainfo.qlen)][[attr, 'Time_TS_searchRecordPF.pkduck', 'setting', 'theta']]\n",
    "\n",
    "        for theta in [0.7, 0.8, 0.9, 1.0]:\n",
    "            print('{}'.format(theta), end='')\n",
    "            for setting in setting_list:\n",
    "                try:\n",
    "                    v = df0[df.theta==theta][df.setting==setting][attr].values[0] - df0[df.theta==theta][df.setting==setting]['Time_TS_searchRecordPF.pkduck'].values[0]/100\n",
    "                    if attr == 'Time_SearchPerQuery_MEAN': print(' & {:,d}'.format(int(v*1000)), end='')\n",
    "                    elif attr == 'Num_Verified' or attr == 'Len_Verified': print(' & {:,}'.format(v), end='')\n",
    "                except:\n",
    "                    print(' & -', end='')\n",
    "            print(' \\\\\\\\\\\\hline')\n",
    "tex_table_filter_power('Time_SearchPerQuery_MEAN')\n",
    "# tex_table_filter_power('Num_Verified')\n",
    "# tex_table_filter_power('Num_Verified', ['RSS-CP', 'RSS-CPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tex_table_filter_power_transposed(attr, setting_list=None):\n",
    "    assert attr in ['Time_SearchPerQuery_MEAN', 'Num_Verified', 'Len_Verified']\n",
    "    if setting_list is None:\n",
    "        setting_list = ['RSS-NAIVE', 'RSS-C', 'RSS-P', 'RSS-L', 'RSS-R', 'RSS-CL', 'RSS-PL', 'RSS-CP', 'RSS-CR', 'RSS-PR', 'PKDUCK-W', 'RSS-CPL', 'RSS-CPR', 'RSS-CLR', 'RSS-PLR', 'RSS-CPLR']\n",
    "    datainfo_list = [\n",
    "            DataInfo('WIKI', '*', '107836', '5', '1.0', '-1'),\n",
    "#             DataInfo('PUBMED', '*', '79011', '5', '1.0', '-1'),\n",
    "#             DataInfo('AMAZON', '*', '107836', '5', '1.0', '-1'),\n",
    "    ]\n",
    "    df = df_from_PrefixSearchFilterPowerTest(setting_list, path='ZeroPrefixSearch.out.repeat10')\n",
    "\n",
    "#     print((' & '.join(['\\\\multirow{2}{*}{$\\\\theta$}']+list(map(lambda x:'\\\\makecell[c]{\\\\textit{'+x+'}}', setting_list)))).replace('RSS-', '') +' \\\\\\\\\\\\hline')\n",
    "    for datainfo in datainfo_list:\n",
    "        df0 = df[df.data_name==datainfo.name][~pd.isnull(df.setting)][df.n==100000][df.nr==int(datainfo.nr)][df.theta>=0.7][df.qlen==int(datainfo.qlen)][[attr, 'Time_TS_searchRecordPF.pkduck', 'setting', 'theta']]\n",
    "        for setting in setting_list:\n",
    "            print(f\"\\\\makecell[c]{{\\\\textit{{{setting.replace('RSS-', '').replace('PKDUCK-W', 'LR')}}}}}\", end='')\n",
    "            for theta in [0.7, 0.8, 0.9, 1.0]:\n",
    "                try:\n",
    "                    v = df0[df.theta==theta][df.setting==setting][attr].values[0] - df0[df.theta==theta][df.setting==setting]['Time_TS_searchRecordPF.pkduck'].values[0]/100\n",
    "                    if attr == 'Time_SearchPerQuery_MEAN': print(f' & {int(v*1000):,}', end='')\n",
    "                    elif attr == 'Num_Verified' or attr == 'Len_Verified': print(f' & {v:,}', end='')\n",
    "                except:\n",
    "                    print(' & -', end='')\n",
    "            print(' \\\\\\\\\\\\hline')\n",
    "#     print(df)\n",
    "tex_table_filter_power_transposed('Time_SearchPerQuery_MEAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tex_compare_index(data_info, setting_list=None):\n",
    "    if setting_list is None: setting_list = ['RSS-C', 'RSS-P', 'PKWISE-R', 'FAERIE-R']\n",
    "#     datainfo_list = [\n",
    "#             DataInfo('WIKI', '100000', nr, '5', '1.0'),\n",
    "#             DataInfo('PUBMED', '100000', nr, '5', '1.0'),\n",
    "#             DataInfo('AMAZON', '100000', nr, '5', '1.0'),\n",
    "#             DataInfo('PUBMED', '100000', nr, '5', '1.0'),\n",
    "#     ]\n",
    "    theta = 0.7\n",
    "#     for data_info in datainfo_list:\n",
    "    df = df_index_stat(data_info)\n",
    "    df = df[df.theta==theta]\n",
    "    for setting in setting_list:\n",
    "        try: t = \"{:.3f}\".format(df[df.setting==setting]['Time_BuildIndex'].values[0])\n",
    "        except: t = '-'\n",
    "        try: s = \"{:,}\".format(df[df.setting==setting]['Space_Index'].values[0])\n",
    "        except: s = '-'\n",
    "        print(' & '.join([str(data_info), setting, t, s]) +' \\\\\\\\\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_index_size_vary_dataset(alg):\n",
    "    dataset_list = ['WIKI', 'AMAZON', 'PUBMED']\n",
    "    SEP = ' '\n",
    "    \n",
    "    def get_df(datainfo):\n",
    "        df = df_time_by_size(datainfo, alg_list=[alg])\n",
    "        if alg.startswith('PrefixSearch'):\n",
    "            return df[df.theta==0.7][df['setting'].isin(['RSS-P'])][['n', 'Space_Index']]\n",
    "        else:\n",
    "            return df[df.theta==0.7][['n', 'Space_Index']]\n",
    "    \n",
    "    with open('data_size.txt') as f:\n",
    "        lines = list(map(str.split, f.readlines()))\n",
    "    dict_data_size = {(x[0], x[1]):x[2] for x in lines}\n",
    "    dict_datainfo = {\n",
    "        'WIKI':DataInfo('WIKI', '*', '107836', '5', '1.0', '10'),\n",
    "        'AMAZON':DataInfo('AMAZON', '*', '107836', '5', '1.0', '10'),\n",
    "        'PUBMED':DataInfo('PUBMED', '*', '79011', '5', '1.0', '10'),\n",
    "    }\n",
    "    dict_df = {x:get_df(dict_datainfo[x]) for x in dataset_list}\n",
    "    \n",
    "    ratio_mat = []\n",
    "    for n in ['10000', '31622', '100000', '316227', '1000000']:\n",
    "        val_list = []\n",
    "        ratio_list = []\n",
    "        for dataset in ['WIKI', 'AMAZON', 'PUBMED']:\n",
    "            df = dict_df[dataset]\n",
    "            size_d = float(dict_data_size[(dataset, n)])/1e6\n",
    "            val_list.append(f\"{size_d:.3f}\")\n",
    "            try: \n",
    "                size_i = float(df[df.n==int(n)]['Space_Index'].item())\n",
    "                ratio_list.append(size_i/size_d)\n",
    "                val_list.append(f\"{size_i:.3f}\")\n",
    "            except:\n",
    "                size_i = '-'\n",
    "                ratio_list.append(0)\n",
    "                val_list.append(size_i)\n",
    "        ratio_mat.append(ratio_list)\n",
    "            \n",
    "        print(f\"$10^{{{np.log10(int(n)):.1f}}}$\"+SEP+SEP.join(val_list)+' \\\\\\\\\\\\hline')\n",
    "    \n",
    "    ratio_arr = np.array(ratio_mat)\n",
    "    print(np.mean(ratio_arr, axis=0))\n",
    "# table_index_size_vary_dataset(\"PrefixSearch_6.32\")\n",
    "# table_index_size_vary_dataset(\"PkwiseSynSearch_2.00\")\n",
    "# table_index_size_vary_dataset(\"FaerieSynSearch_1.02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_index_size_vary_alg(datainfo, alg_list):\n",
    "    SEP = ' & '\n",
    "    \n",
    "    def get_df(alg):\n",
    "        df = df_time_by_size(datainfo, alg_list=[alg])\n",
    "        if len(df) == 0: return None\n",
    "        if alg.startswith('PrefixSearch'):\n",
    "            return df[df.theta==0.7][df['setting'].isin(['RSS-CP'])][['n', 'Space_Index']]\n",
    "        else:\n",
    "            return df[df.theta==0.7][['n', 'Space_Index']]\n",
    "    \n",
    "    with open('data_size.txt') as f:\n",
    "        lines = list(map(str.split, f.readlines()))\n",
    "    dict_data_size = {(x[0], x[1]):x[2] for x in lines}\n",
    "\n",
    "    dict_df = {x:get_df(x) for x in alg_list}\n",
    "    \n",
    "    ratio_mat = []\n",
    "    for n in ['10000', '31622', '100000', '316227', '1000000', '3162277', '10000000']:\n",
    "        val_list = []\n",
    "        ratio_list = []\n",
    "        size_d = float(dict_data_size[(datainfo.name, n)])/1e6\n",
    "        val_list.append(f\"{size_d:.3f}\")\n",
    "        for alg in alg_list:\n",
    "            df = dict_df[alg]\n",
    "            try: \n",
    "                size_i = float(df[df.n==int(n)]['Space_Index'].item())\n",
    "                ratio_list.append(size_i/size_d)\n",
    "                val_list.append(f\"{size_i:.3f}\")\n",
    "            except:\n",
    "                size_i = '-'\n",
    "                ratio_list.append(0)\n",
    "                val_list.append(size_i)\n",
    "        ratio_mat.append(ratio_list)\n",
    "            \n",
    "        print(f\"$10^{{{np.log10(int(n)):.1f}}}$\"+SEP+SEP.join(val_list)+' \\\\\\\\\\\\hline')\n",
    "    \n",
    "    ratio_arr = np.array(ratio_mat)\n",
    "    print(np.mean(ratio_arr, axis=0))\n",
    "# datainfo = DataInfo('WIKI', '*', '107836', '5', '1.0', NAR)\n",
    "# table_index_size_vary_alg(datainfo, [\"PrefixSearch_6.32\", \"PkwiseSynSearch_2.00\", \"FaerieSynSearch_1.02\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_filter_verify():\n",
    "    dataset_list = ['WIKI', 'AMAZON', 'PUBMED']\n",
    "    dict_datainfo = {\n",
    "        'WIKI':DataInfo('WIKI', '*', '107836', '5', '1.0', '-1'),\n",
    "        'AMAZON':DataInfo('AMAZON', '*', '107836', '5', '1.0', '-1'),\n",
    "        'PUBMED':DataInfo('PUBMED', '*', '79011', '5', '1.0', '-1'),\n",
    "    }\n",
    "    SEP = ' & '\n",
    "\n",
    "    def get_df(datainfo):\n",
    "        df = df_time_by_size(datainfo, alg_list=[\"PrefixSearch_6.32\"])\n",
    "        return  df[df.theta==0.7][df['setting'].isin(['RSS-CPL'])][['n', 'nq', 'Time_IndexFilter', 'Time_Validation']]\n",
    "\n",
    "    with open('data_size.txt') as f:\n",
    "        lines = list(map(str.split, f.readlines()))\n",
    "    dict_data_size = {(x[0], x[1]):x[2] for x in lines}\n",
    "    dict_datainfo = {\n",
    "        'WIKI':DataInfo('WIKI', '*', '107836', '5', '1.0', '-1'),\n",
    "        'AMAZON':DataInfo('AMAZON', '*', '107836', '5', '1.0', '-1'),\n",
    "        'PUBMED':DataInfo('PUBMED', '*', '79011', '5', '1.0', '-1'),\n",
    "    }\n",
    "    dict_df = {x:get_df(dict_datainfo[x]) for x in dataset_list}\n",
    "    \n",
    "    ratio_mat = []\n",
    "    for n in ['10000', '31622', '100000', '316227', '1000000']:\n",
    "        val_list = []\n",
    "        ratio_list = []\n",
    "        for dataset in ['WIKI', 'AMAZON', 'PUBMED']:\n",
    "            df = dict_df[dataset]\n",
    "            t_f = float(df[df.n==int(n)]['Time_IndexFilter'].item())/int(df[df.n==int(n)]['nq'])*1000 # ms\n",
    "            t_v = float(df[df.n==int(n)]['Time_Validation'].item())/int(df[df.n==int(n)]['nq'])*1000 # ms\n",
    "            ratio_list.append(t_f/t_v)\n",
    "            val_list += [t_f, t_v]\n",
    "        ratio_mat.append(ratio_list)\n",
    "            \n",
    "        print(f\"$10^{{{np.log10(int(n)):.1f}}}$\"+SEP+SEP.join(map(lambda x: f\"{x:.3f}\", val_list))+' \\\\\\\\\\\\hline')\n",
    "    \n",
    "    print(pd.DataFrame(ratio_mat))\n",
    "    print(pd.DataFrame(ratio_mat).min(axis=0))\n",
    "# compare_filter_verify()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
